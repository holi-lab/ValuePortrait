<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project page of the paper, Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items">
  <meta property="og:title" content="Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items"/>
  <meta property="og:description" content="Value Portrait: A reliable benchmark for understanding LLMs' value orientations across diverse real-world scenarios"/>
  <meta property="og:url" content="https://holi-lab.github.io/ValuePortrait"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/framework.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="450"/>


  <meta name="twitter:title" content="Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items">
  <meta name="twitter:description" content="Value Portrait: A reliable benchmark for understanding LLMs' value orientations across diverse real-world scenarios">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/framework.png">
  <meta name="twitter:card" content="Value Portrait: Assessing Language Models' Values">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Language models, Values, Benchmark, Psychometrics">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jongwook-han.github.io/" target="_blank">Jongwook Han</a>,&nbsp</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=9AlW_GAAAAAJ&hl=ko" target="_blank">Dongmin Choi</a>,&nbsp</span>
                <span class="author-block">
                  <a href="https://github.com/opusdeisong" target="_blank">Woojung Song</a>,&nbsp</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=LPVWCwsAAAAJ&hl=ko&oi=ao" target="_blank">Eun-Ju Lee</a>,&nbsp</span>
                  <span class="author-block">
                    <a href="https://yohanjo.github.io/" target="_blank">Yohan Jo</a></span>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Seoul National University,&nbsp</span><br>ACL 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.01015.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/holi-lab/ValuePortrait" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code & Data </span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.01015" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="subtitle has-text-centered">
      <b>TL; DR.</b> Value Portrait is a benchmark for assessing the values of language models across diverse real-world scenarios.
    </h2>
    <div class="hero-body">
      <img src="static/images/framework.png" alt="Value Portrait Framework" id="teaser" width="100%">
    </div>
  </div>
</section>
<!-- End teaser video -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The importance of benchmarks for assessing the values of language models has been pronounced due to the growing need of more authentic, human-aligned responses. However, existing benchmarks rely on human or machine annotations that are vulnerable to value-related biases. Furthermore, the tested scenarios often diverge from real-world contexts in which models are commonly used to generate text and express values. To address these issues, we propose the Value Portrait benchmark, a reliable framework for evaluating LLMs' value orientations with two key characteristics. First, the benchmark consists of items that capture real-life user-LLM interactions, enhancing the relevance of assessment results to real-world LLM usage. Second, each item is rated by human subjects based on its similarity to their own thoughts, and correlations between these ratings and the subjects' actual value scores are derived. This psychometrically validated approach ensures that items strongly correlated with specific values serve as reliable items for assessing those values. Through evaluating 44 LLMs with our benchmark, we find that these models prioritize Benevolence, Security, and Self-Direction values while placing less emphasis on Tradition, Power, and Achievement values. Also, our analysis reveals biases in how LLMs perceive various demographic groups, deviating from real human data.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Motivation -->
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 is-centered has-text-centered">Motivation</h2>

    <p>Existing works measure the <b>perceived</b> values that annotators believe the text expresses. However, this approach does not guarantee whether a person who prioritizes a certain value actually says the text.</p>

    <p>Also, existing value-oriented datasets either focus on safety scenarios or rely heavily on standardized psychometric questionnaires. Hence, they do not comprehensively capture the diverse range of real-world scenarios in
      which LLMs are commonly used and express their
      values (through generated text).</p>

    <p>This motivated us to us to construct Value Portrait using a carefully curated set of human-LLM conversations from ShareGPT and LMSYS, supplemented with human-to-human advisory interactions from Reddit and DearAbby archives.</p>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <img src="static/images/introduction.png" alt="Value Portrait Motivation" width="100%">
        </div>
      </div>
    </div>
<!-- End Motivation -->

<!-- Evaluation Framework -->
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 is-centered has-text-centered">Evaluation Framework</h2>
    <p>Our evaluation framework is organized into three key steps: <br><b>(1)</b> filtering query-response pairs, <br><b>(2)</b> collecting responses from LLMs, and <br><b>(3)</b> assessing their value orientations.</p>

    <p>First, for each value dimension, we retain items
      with correlations of at least 0.3 (with p-value <
      0.05) with their corresponding value.</p> 
    <p>Second, we present each item to the LLMs and collect their ratings using a 6-point Likert scale. For each item, we ask "How similar is this response
      to your own thoughts?"—maintaining consistency
      with our dataset construction methodology.</p>
    
    <p>Since LLMs exhibit sensitivity to prompts we use six prompts in our evaluation. Three prompts were adapted from previous works to suit our research context, and the other three were obtained by reversing their order of options. The final results are obtained by averaging the responses of the LLM from the six prompts.</p>
    <p>For the final step, the evaluation of an LLM’s value orientation follows a two-step process: <br><b>(1)</b> calculate the mean score for each value dimension across its corresponding items, and <br><b>(2)</b> adjust each score by subtracting the average of all item responses. This methodology, adapted from Schwartz’s research on human value assessment, enables us to identify relative value priorities by adjusting for differences in how LLMs use response scales. These normalized scores across value dimensions represent LLM’s value orientations.</p>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <img src="static/images/filtering.png" alt="Filtering Process" width="100%">
        </div>
      </div>
    </div>
 </section>
 <!-- End Evaluation Framework -->

 <!-- Results -->
 <section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 is-centered has-text-centered">Results</h2>
    <p>We evaluate 44 LLMs with our benchmark and find that these models prioritize Benevolence, Security, and Self-Direction values while placing less emphasis on Tradition, Power, and Achievement values.</p>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <img src="static/images/results.png" alt="Results" width="100%">
        </div>
      </div>
    </div>
 </section>
 <!-- End Results -->

 <!-- Gender Bias Analysis -->
 <section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 is-centered has-text-centered">Bias Analysis</h2>
    <p>Our analysis reveals biases in how LLMs perceive various demographic groups, deviating from real human data. This comprehensive evaluation helps identify and address value-related biases in language models.</p>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <img src="static/images/bias_gender.png" alt="Gender Bias Analysis" width="100%">
        </div>
      </div>
    </div>
    <br>

    


    <!-- Toggle Button ABOVE the content -->
    <div class="has-text-centered">
      <button class="button is-link is-light" onclick="toggleBiasResults()">Click for more results</button>
    </div>

    <!-- Hidden Section STARTS here -->
    <div id="bias-results-section" style="display: none;">

      <h2 class="title is-5">Education Bias Analysis</h2>
      <p>
        Our analysis reveals biases in how LLMs perceive different educational backgrounds, showing significant deviations from human value patterns across various education levels.
      </p>

      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <img src="static/images/bias_education.png" alt="Education Bias Analysis" width="100%">
            <p class="has-text-centered">
              Bias analysis across different educational backgrounds
            </p>
          </div>
        </div>
      </div>

      <h2 class="title is-5">Political Orientation Bias Analysis</h2>
      <p>
        We examine how LLMs exhibit biases in value orientations based on political orientations, revealing systematic differences that diverge from real human data patterns.
      </p>

      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <img src="static/images/bias_political_orientation.png" alt="Political Orientation Bias Analysis" width="100%">
            <p class="has-text-centered">
              Bias analysis across different political orientations
            </p>
          </div>
        </div>
      </div>

    </div>
    <br>

<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{han2025value,
        title={Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items},
        author={Han, Jongwook and Choi, Dongmin and Song, Woojung and Lee, Eun-Ju and Jo, Yohan},
        journal={arXiv preprint arXiv:2505.01015},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

    <!-- Toggle Script for Bias Analysis -->
    <script>
      function toggleBiasResults() {
        const section = document.getElementById("bias-results-section");
        section.style.display = section.style.display === "none" ? "block" : "none";
      }
    </script>
  </body>
  </html>
